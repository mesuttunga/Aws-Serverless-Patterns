# Lambda Image Processing Pipeline

Event-driven image compression service using AWS Lambda and S3. Images uploaded to source bucket automatically trigger Lambda function for compression and storage in optimized bucket.

## ðŸ—ï¸ Architecture

```
User Upload
    â†“
S3 Source Bucket (yourbucket-s3)
    â†“
S3 Event Notification
    â†“
Lambda Function (Node.js)
    â”œâ”€ Download image
    â”œâ”€ Compress image
    â””â”€ Upload to destination
         â†“
S3 Compressed Bucket (yourbucket-s3-compressed)
```

### Event Flow
1. User uploads image to `yourbucket-s3` bucket
2. S3 triggers Lambda via event notification
3. Lambda downloads original image
4. Image compressed using Sharp library
5. Compressed image uploaded to `yourbucket-s3-compressed`
6. CloudWatch logs capture processing metrics

## ðŸ’¡ Key Features

- **Automatic Processing** - No manual intervention required
- **Cost Efficient** - Pay only when images are uploaded
- **Scalable** - Lambda auto-scales with upload volume
- **Format Support** - JPG, PNG, GIF formats
- **Size Optimization** - Typical 60-80% size reduction

## ðŸ“‚ Project Structure

```
lambda-image-processing/
â”œâ”€â”€ README.md
â”œâ”€â”€ upload.php
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ index.js           # Lambda handler
â”‚   â””â”€â”€ package.json       # Dependencies
â””â”€â”€ terraform/
    â”œâ”€â”€ main.tf           # Infrastructure definition
    â”œâ”€â”€ variables.tf      # Input variables
    â”œâ”€â”€ outputs.tf        # Stack outputs
    â””â”€â”€ README.md
```

## ðŸš€ Deployment

### Prerequisites
- AWS CLI configured
- Terraform >= 1.0
- Node.js 18.x

### Quick Deploy

1. **Package Lambda function:**
```bash
cd lambda
npm install
zip -r function.zip index.js node_modules/
```

2. **Deploy with Terraform:**
```bash
cd terraform
terraform init
terraform plan
terraform apply
```

3. **Configure S3 event notification:**
```bash
aws s3api put-bucket-notification-configuration \
  --bucket yourbucket-s3 \
  --notification-configuration '{
    "LambdaFunctionConfigurations": [{
      "LambdaFunctionArn": "arn:aws:lambda:eu-west-2:ACCOUNT:function:ImageCompressor",
      "Events": ["s3:ObjectCreated:*"],
      "Filter": {
        "Key": {
          "FilterRules": [{
            "Name": "suffix",
            "Value": ".jpg"
          }]
        }
      }
    }]
  }'
```

## ðŸ§ª Testing

### Upload test image:
```bash
aws s3 cp test-image.jpg s3://yourbucket-s3/uploads/test-image.jpg
```

### Check Lambda execution:
```bash
aws logs tail /aws/lambda/ImageCompressor --follow
```

### Verify compressed output:
```bash
aws s3 ls s3://yourbucket-s3-compressed/uploads/
```

## âš™ï¸ Lambda Configuration

```javascript
// index.js
const AWS = require('aws-sdk');
const sharp = require('sharp');
const s3 = new AWS.S3();

exports.handler = async (event) => {
  const bucket = event.Records[0].s3.bucket.name;
  const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));
  
  // Download original
  const originalImage = await s3.getObject({
    Bucket: bucket,
    Key: key
  }).promise();
  
  // Compress image
  const compressedImage = await sharp(originalImage.Body)
    .jpeg({ quality: 80 })
    .toBuffer();
  
  // Upload compressed version
  await s3.putObject({
    Bucket: 'yourbucket-s3-compressed',
    Key: key,
    Body: compressedImage,
    ContentType: 'image/jpeg'
  }).promise();
  
  return {
    statusCode: 200,
    body: `Compressed ${key}`
  };
};
```

### Function Settings
- **Runtime:** Node.js 18.x
- **Memory:** 512 MB
- **Timeout:** 60 seconds
- **Layer:** Sharp (image processing library)

## ðŸ“Š Monitoring

### CloudWatch Metrics to Track
- **Invocations** - Number of images processed
- **Duration** - Processing time per image
- **Errors** - Failed compressions
- **Throttles** - Rate limiting events

### Sample CloudWatch Insights Query
```sql
fields @timestamp, @message
| filter @message like /Compressed/
| stats count() as ProcessedImages by bin(5m)
```

## ðŸ”§ Error Handling

Lambda implements comprehensive error handling:

```javascript
try {
  // Image processing
} catch (error) {
  if (error.code === 'NoSuchKey') {
    console.error('Source image not found');
  } else if (error.code === 'InvalidImageFormat') {
    console.error('Unsupported image format');
  }
  
  // Send to DLQ for investigation
  await sqs.sendMessage({
    QueueUrl: process.env.DLQ_URL,
    MessageBody: JSON.stringify({
      error: error.message,
      bucket: bucket,
      key: key
    })
  }).promise();
  
  throw error;
}
```

## ðŸ’° Cost Breakdown (September 2025)

For 10,000 images/month (avg 2MB each):

- **Lambda Requests:** $0.20 (10K invocations)
- **Lambda Compute:** $0.83 (512MB, 3s avg duration)
- **S3 Storage:** $0.46 (20GB total)
- **Data Transfer:** $0.90 (10GB out)
- **Total:** ~$2.39/month

## ðŸŽ¯ Production Enhancements

**Implemented:**
- âœ… Dead letter queue for failed processing
- âœ… CloudWatch logging and metrics
- âœ… IAM least privilege permissions
- âœ… S3 versioning for source bucket

**Future Improvements:**
- Multi-format output (WebP, AVIF)
- Image resizing (thumbnails, multiple sizes)
- Metadata extraction
- SNS notification on completion
- Step Functions for complex workflows

## ðŸ“š Related Resources

- [AWS Lambda with S3](https://docs.aws.amazon.com/lambda/latest/dg/with-s3.html)
- [Sharp Image Processing](https://sharp.pixelplumbing.com/)
- [S3 Event Notifications](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)

---

**Pattern Status:** Production-tested âœ…  
**Last Updated:** September 2025